{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                        0\n",
       "Overall Rank                                                      1\n",
       "School                           California Institute of Technology\n",
       "State                                                            CA\n",
       "Undergrad. Enrollment                                     0.0448952\n",
       "Admission Rate                                             0.109375\n",
       "Student/faculty Ratio                                             0\n",
       "4-year Grad. Rate                                          0.797753\n",
       "6-year Grad. Rate                                           0.62963\n",
       "Quality Rank                                                     10\n",
       "Total Costs                                                0.764995\n",
       "Cost After Need-based Aid                                  0.233873\n",
       "Need Met                                                          1\n",
       "Aid From Grants                                             0.90411\n",
       "Cost After Non-Need-Based Aid                              0.354043\n",
       "Non-Need-Based Aid+                                        0.141414\n",
       "Average Debt                                               0.363044\n",
       "Cost Rank                                                         4\n",
       "SAT                                                        0.980392\n",
       "ACT                                                               1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data/normalised_college_dataset.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>6-year Grad. Rate</th>\n",
       "      <th>Average Debt</th>\n",
       "      <th>Non-Need-Based Aid+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.363044</td>\n",
       "      <td>0.141414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.450260</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.452174</td>\n",
       "      <td>0.010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.202006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.554063</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACT  6-year Grad. Rate  Average Debt  Non-Need-Based Aid+\n",
       "0  1.000000           0.629630      0.363044             0.141414\n",
       "1  0.822222           0.777778      0.450260             0.333333\n",
       "2  0.955556           0.888889      0.452174             0.010101\n",
       "3  1.000000           0.555556      0.202006             1.000000\n",
       "4  0.755556           0.777778      0.554063             0.303030"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = data[['ACT','6-year Grad. Rate','Average Debt','Non-Need-Based Aid+']].copy()\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(x):\n",
    "    if (x>=0.5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['ACT'] = final_df['ACT'].apply(classify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df['Non-Need-Based Aid+'] = final_df['Non-Need-Based Aid+'].apply(classify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df['6-year Grad. Rate'] = final_df['6-year Grad. Rate'].apply(classify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df['Average Debt'] = final_df['Average Debt'].apply(classify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>6-year Grad. Rate</th>\n",
       "      <th>Average Debt</th>\n",
       "      <th>Non-Need-Based Aid+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACT  6-year Grad. Rate  Average Debt  Non-Need-Based Aid+\n",
       "0    1                  1             0                    0\n",
       "1    1                  1             0                    0\n",
       "2    1                  1             0                    0\n",
       "3    1                  1             0                    1\n",
       "4    1                  1             1                    0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "dataset = final_df # list of transactions; each transaction is a list of items\n",
    "D = list(map(set, dataset)) # set of transactions; each transaction is a list of items\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ff = dataset.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df_l):\n",
    "    l_f = []\n",
    "    for item in df_l:\n",
    "        l_t = []\n",
    "        #print(item)\n",
    "        for i in range(0,4):\n",
    "            if(i==0):\n",
    "                if(item[i]==1):\n",
    "                    l_t.append('A')\n",
    "            elif(i==1):\n",
    "                if(item[i]==1):\n",
    "                    l_t.append('B')\n",
    "            elif(i==2):\n",
    "                if(item[i]==1):\n",
    "                    l_t.append('C')        \n",
    "            else:\n",
    "                if(item[i]==1):\n",
    "                    l_t.append('D')\n",
    "        l_f.append(l_t)\n",
    "    return(l_f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B'], ['A', 'B'], ['A', 'B'], ['A', 'B', 'D'], ['A', 'B', 'C'], ['A', 'B', 'C'], ['A', 'B', 'C'], ['A', 'B'], ['A', 'B', 'C'], ['A', 'B', 'C'], ['A', 'B'], ['A', 'D'], ['A', 'B'], ['A', 'B', 'C'], ['A', 'B', 'C'], [], ['A', 'B', 'C'], ['A', 'B', 'C'], ['A', 'B', 'C'], ['A', 'B', 'D'], ['A', 'B', 'C'], ['A'], ['A', 'B'], ['A', 'B'], ['B', 'C'], ['A', 'B', 'C', 'D'], ['A', 'B', 'C'], ['A', 'B', 'C'], ['A', 'B', 'C'], ['A'], ['C'], ['C', 'D'], ['A', 'B', 'C'], ['C'], ['C'], ['A', 'B', 'C'], ['C', 'D'], ['A', 'C'], ['A', 'B', 'C'], ['A', 'D'], ['A', 'B', 'C'], ['A', 'C', 'D'], ['A'], ['B', 'C'], ['A', 'C'], ['A', 'C', 'D'], ['C'], ['A', 'B', 'C'], ['C'], ['A', 'D'], ['A', 'C'], ['B', 'C'], ['C'], ['A', 'C', 'D'], ['C'], [], ['B', 'C'], ['A', 'C'], []]\n"
     ]
    }
   ],
   "source": [
    "dataset_ff = process(dataset_ff)\n",
    "print(dataset_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3-Qms981jt9"
   },
   "outputs": [],
   "source": [
    "def create_candidates(dataset, VERBOSE=False):\n",
    "    \"\"\"Creates a list of candidate 1-itemsets from a list of transactions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate candidate \n",
    "        itemsets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The list of candidate itemsets (c1) passed as a frozenset (a set that is \n",
    "    immutable and hashable).\n",
    "    \"\"\"\n",
    "    c1 = [] # list of all items in the database of transactions\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            if not [item] in c1:\n",
    "                c1.append([item])\n",
    "    c1.sort()\n",
    "\n",
    "    if VERBOSE:\n",
    "        # Print a list of all the candidate items.\n",
    "        print (\"\" \\\n",
    "            + \"{\" \\\n",
    "            + \"\".join(str(i[0]) + \", \" for i in iter(c1)).rstrip(', ') \\\n",
    "            + \"}\")\n",
    "\n",
    "    # Map c1 to a frozenset because it will be the key of a dictionary.\n",
    "    return list(map(frozenset, c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FpFZo6K778OX",
    "outputId": "ff612e9b-a318-480c-9f29-e3b4b594ea64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{A, B, C, D}\n"
     ]
    }
   ],
   "source": [
    "# Generate candidate itemsets.\n",
    "C1 = create_candidates(dataset_ff, VERBOSE=True) # candidate 1-itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNCB3kH9J4VP"
   },
   "source": [
    "**Now a function is defined to prune the candidates from the database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92M3wSFTJ_pm"
   },
   "outputs": [],
   "source": [
    "def support_prune(dataset, candidates, min_support, VERBOSE=False):\n",
    "    \"\"\"Returns all candidate itemsets that meet a minimum support threshold.\n",
    "\n",
    "    By the apriori principle, if an itemset is frequent, then all of its \n",
    "    subsets must also be frequent. As a result, we can perform support-based \n",
    "    pruning to systematically control the exponential growth of candidate \n",
    "    itemsets. Thus, itemsets that do not meet the minimum support level are \n",
    "    pruned from the input list of itemsets (dataset).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate candidate \n",
    "        itemsets.\n",
    "\n",
    "    candidates : frozenset\n",
    "        The list of candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    retlist : list\n",
    "        The list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "    \"\"\"\n",
    "    sscnt = {} # set for support counts\n",
    "    num_items=0\n",
    "    for tid in dataset:\n",
    "        num_items+=1\n",
    "        for candidate in candidates:\n",
    "            if candidate.issubset(tid):\n",
    "                sscnt.setdefault(candidate, 0)\n",
    "                sscnt[candidate] += 1\n",
    "\n",
    "    #num_items = 5 #len(dataset) # total number of transactions in the dataset\n",
    "    retlist = [] # array for unpruned itemsets\n",
    "    support_data = {} # set for support data for corresponding itemsets\n",
    "    for key in sscnt:\n",
    "        # Calculate the support of itemset key.\n",
    "        support = sscnt[key] / num_items\n",
    "        if support >= min_support:\n",
    "            retlist.insert(0, key)\n",
    "        support_data[key] = support\n",
    "\n",
    "    # Print a list of the pruned itemsets.\n",
    "    if VERBOSE:\n",
    "        for kset in retlist:\n",
    "            for item in kset:\n",
    "                print (\"{\" + str(item) + \"}\")\n",
    "        #print\n",
    "        for key in sscnt:\n",
    "            print (\"\" \\\n",
    "                + \"{\" \\\n",
    "                + \"\".join([str(i) + \", \" for i in iter(key)]).rstrip(', ') \\\n",
    "                + \"}\" \\\n",
    "                + \":  sup = \" + str(support_data[key]))\n",
    "\n",
    "    return retlist, support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TIi-Pa-18DVw",
    "outputId": "9d1dbb4d-b54f-4eef-a7a6-d3f21e66c5b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{A}:  sup = 0.7288135593220338\n",
      "{B}:  sup = 0.576271186440678\n",
      "{D}:  sup = 0.1864406779661017\n",
      "{C}:  sup = 0.6779661016949152\n"
     ]
    }
   ],
   "source": [
    "# Prune candidate 1-itemsets via support-based pruning to generate frequent 1-itemsets.\n",
    "F1, support_data = support_prune(dataset_ff, C1, 0.8, VERBOSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrAAUmI2KBYs"
   },
   "outputs": [],
   "source": [
    "def apriori(dataset, min_support=0.5, VERBOSE=False):\n",
    "    \"\"\"Implements the Apriori algorithm.\n",
    "\n",
    "    The Apriori algorithm will iteratively generate new candidate \n",
    "    k-itemsets using the frequent (k-1)-itemsets found in the previous \n",
    "    iteration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F : list\n",
    "        The list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    C1 = create_candidates(dataset)\n",
    "    D = list(map(set, dataset))\n",
    "    F1, support_data = support_prune(D, C1, min_support, VERBOSE=False) # prune candidate 1-itemsets\n",
    "    F = [F1] # list of frequent itemsets; initialized to frequent 1-itemsets\n",
    "    k = 2 # the itemset cardinality\n",
    "    while (len(F[k - 2]) > 0):\n",
    "        Ck = apriori_gen(F[k-2], k) # generate candidate itemsets\n",
    "        Fk, supK = support_prune(D, Ck, min_support) # prune candidate itemsets\n",
    "        support_data.update(supK) # update the support counts to reflect pruning\n",
    "        F.append(Fk) # add the pruned candidate itemsets to the list of frequent itemsets\n",
    "        k += 1\n",
    "\n",
    "    if VERBOSE:\n",
    "        # Print a list of all the frequent itemsets.\n",
    "        for kset in F:\n",
    "            for item in kset:\n",
    "                print( \"\" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join(str(i) + \", \" for i in iter(item)).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \":  sup = \" + str(round(support_data[item], 3)))\n",
    "\n",
    "    return F, support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8X3orG5QtX1"
   },
   "outputs": [],
   "source": [
    "def apriori_gen(freq_sets, k):\n",
    "    \"\"\"Generates candidate itemsets (via the F_k-1 x F_k-1 method).\n",
    "\n",
    "    This operation generates new candidate k-itemsets based on the frequent \n",
    "    (k-1)-itemsets found in the previous iteration. The candidate generation \n",
    "    procedure merges a pair of frequent (k-1)-itemsets only if their first k-2 \n",
    "    items are identical.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_sets : list\n",
    "        The list of frequent (k-1)-itemsets.\n",
    "\n",
    "    k : integer\n",
    "        The cardinality of the current itemsets begin evaluated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    retlist : list\n",
    "        The list of merged frequent itemsets.\n",
    "    \"\"\"\n",
    "    retList = [] # list of merged frequent itemsets\n",
    "    lenLk = len(freq_sets) # number of frequent itemsets\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            a=list(freq_sets[i])\n",
    "            b=list(freq_sets[j])\n",
    "            a.sort()\n",
    "            b.sort()\n",
    "            F1 = a[:k-2] # first k-2 items of freq_sets[i]\n",
    "            F2 = b[:k-2] # first k-2 items of freq_sets[j]\n",
    "\n",
    "            if F1 == F2: # if the first k-2 items are identical\n",
    "                # Merge the frequent itemsets.\n",
    "                retList.append(freq_sets[i] | freq_sets[j])\n",
    "\n",
    "    return retList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "POdWUhDMTOqZ",
    "outputId": "35d10cba-6ea1-4c49-fc38-83b1638f4b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{C}:  sup = 0.678\n",
      "{D}:  sup = 0.186\n",
      "{B}:  sup = 0.576\n",
      "{A}:  sup = 0.729\n",
      "{C, D}:  sup = 0.102\n",
      "{A, C}:  sup = 0.458\n",
      "{B, C}:  sup = 0.407\n",
      "{A, D}:  sup = 0.153\n",
      "{B, D}:  sup = 0.051\n",
      "{B, A}:  sup = 0.508\n",
      "{A, C, D}:  sup = 0.068\n",
      "{B, A, C}:  sup = 0.339\n",
      "{B, A, D}:  sup = 0.051\n"
     ]
    }
   ],
   "source": [
    "# Generate all the frequent itemsets using the Apriori algorithm.\n",
    "F, support_data = apriori(dataset_ff, min_support=0.02, VERBOSE=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZCRcIqCVY-S"
   },
   "source": [
    "Now Functions to generate Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILTy7Kl4Twnj"
   },
   "outputs": [],
   "source": [
    "def rules_from_conseq(freq_set, H, support_data, rules, min_confidence=0.7):\n",
    "    \"\"\"Generates a set of candidate rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_set : frozenset\n",
    "        The complete list of frequent itemsets.\n",
    "\n",
    "    H : list\n",
    "        A list of frequent itemsets (of a particular length).\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "\n",
    "    rules : list\n",
    "        A potentially incomplete set of candidate rules above the minimum \n",
    "        confidence threshold.\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.7.\n",
    "    \"\"\"\n",
    "    m = len(H[0])\n",
    "    if (len(freq_set) > (m+1)):\n",
    "        Hmp1 = apriori_gen(H, m+1) # generate candidate itemsets\n",
    "        Hmp1 = calc_confidence(freq_set, Hmp1,  support_data, rules, min_confidence)\n",
    "        if len(Hmp1) > 1:\n",
    "            # If there are candidate rules above the minimum confidence \n",
    "            # threshold, recurse on the list of these candidate rules.\n",
    "            rules_from_conseq(freq_set, Hmp1, support_data, rules, min_confidence)\n",
    "\n",
    "def calc_confidence(freq_set, H, support_data, rules, min_confidence=0.7, VERBOSE=False):\n",
    "    \"\"\"Evaluates the generated rules.\n",
    "\n",
    "    One measurement for quantifying the goodness of association rules is \n",
    "    confidence. The confidence for a rule 'P implies H' (P -> H) is defined as \n",
    "    the support for P and H divided by the support for P \n",
    "    (support (P|H) / support(P)), where the | symbol denotes the set union \n",
    "    (thus P|H means all the items in set P or in set H).\n",
    "\n",
    "    To calculate the confidence, we iterate through the frequent itemsets and \n",
    "    associated support data. For each frequent itemset, we divide the support \n",
    "    of the itemset by the support of the antecedent (left-hand-side of the \n",
    "    rule).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_set : frozenset\n",
    "        The complete list of frequent itemsets.\n",
    "\n",
    "    H : list\n",
    "        A frequent itemset.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold.\n",
    "\n",
    "    rules : list\n",
    "        A potentially incomplete set of candidate rules above the minimum \n",
    "        confidence threshold.\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.7.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pruned_H : list\n",
    "        The list of candidate rules above the minimum confidence threshold.\n",
    "    \"\"\"\n",
    "    pruned_H = [] # list of candidate rules above the minimum confidence threshold\n",
    "    for conseq in H: # iterate over the frequent itemsets\n",
    "        conf = support_data[freq_set] / support_data[freq_set - conseq]\n",
    "        if conf >= min_confidence:\n",
    "\n",
    "            rules.append((freq_set - conseq, conseq, conf))\n",
    "            pruned_H.append(conseq)\n",
    "\n",
    "            if VERBOSE:\n",
    "                print( \"\" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join([str(i) + \", \" for i in iter(freq_set-conseq)]).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \" ---> \" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join([str(i) + \", \" for i in iter(conseq)]).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \":  conf = \" + str(round(conf, 3)) \\\n",
    "                    + \", sup = \" + str(round(support_data[freq_set], 3)))\n",
    "\n",
    "    return pruned_H\n",
    "\n",
    "def generate_rules(F, support_data, min_confidence, VERBOSE=False):\n",
    "    \"\"\"Generates a set of candidate rules from a list of frequent itemsets.\n",
    "\n",
    "    For each frequent itemset, we calculate the confidence of using a\n",
    "    particular item as the rule consequent (right-hand-side of the rule). By \n",
    "    testing and merging the remaining rules, we recursively create a list of \n",
    "    pruned rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    F : list\n",
    "        A list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The corresponding support data for the frequent itemsets (L).\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.7.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rules : list\n",
    "        The list of candidate rules above the minimum confidence threshold.\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    for i in range(1, len(F)):\n",
    "        for freq_set in F[i]:\n",
    "            H1 = [frozenset([item]) for item in freq_set]\n",
    "\n",
    "            if (i > 1):\n",
    "                rules_from_conseq(freq_set, H1, support_data, rules, min_confidence)\n",
    "            else:\n",
    "                calc_confidence(freq_set, H1, support_data, rules, min_confidence, VERBOSE=VERBOSE)\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSQNfAJHVejn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{D} ---> {C}:  conf = 0.545, sup = 0.102\n",
      "{C} ---> {D}:  conf = 0.15, sup = 0.102\n",
      "{C} ---> {A}:  conf = 0.675, sup = 0.458\n",
      "{A} ---> {C}:  conf = 0.628, sup = 0.458\n",
      "{C} ---> {B}:  conf = 0.6, sup = 0.407\n",
      "{B} ---> {C}:  conf = 0.706, sup = 0.407\n",
      "{D} ---> {A}:  conf = 0.818, sup = 0.153\n",
      "{A} ---> {D}:  conf = 0.209, sup = 0.153\n",
      "{D} ---> {B}:  conf = 0.273, sup = 0.051\n",
      "{B} ---> {D}:  conf = 0.088, sup = 0.051\n",
      "{A} ---> {B}:  conf = 0.698, sup = 0.508\n",
      "{B} ---> {A}:  conf = 0.882, sup = 0.508\n",
      "[(frozenset({'D'}), frozenset({'C'}), 0.5454545454545455), (frozenset({'C'}), frozenset({'D'}), 0.15000000000000002), (frozenset({'C'}), frozenset({'A'}), 0.675), (frozenset({'A'}), frozenset({'C'}), 0.627906976744186), (frozenset({'C'}), frozenset({'B'}), 0.6000000000000001), (frozenset({'B'}), frozenset({'C'}), 0.7058823529411765), (frozenset({'D'}), frozenset({'A'}), 0.8181818181818182), (frozenset({'A'}), frozenset({'D'}), 0.2093023255813954), (frozenset({'D'}), frozenset({'B'}), 0.27272727272727276), (frozenset({'B'}), frozenset({'D'}), 0.08823529411764706), (frozenset({'A'}), frozenset({'B'}), 0.6976744186046512), (frozenset({'B'}), frozenset({'A'}), 0.8823529411764706), (frozenset({'D'}), frozenset({'A', 'C'}), 0.36363636363636365), (frozenset({'C'}), frozenset({'A', 'D'}), 0.1), (frozenset({'A'}), frozenset({'C', 'D'}), 0.0930232558139535), (frozenset({'C'}), frozenset({'B', 'A'}), 0.5), (frozenset({'A'}), frozenset({'B', 'C'}), 0.46511627906976744), (frozenset({'B'}), frozenset({'A', 'C'}), 0.588235294117647), (frozenset({'D'}), frozenset({'B', 'A'}), 0.27272727272727276), (frozenset({'A'}), frozenset({'B', 'D'}), 0.06976744186046513), (frozenset({'B'}), frozenset({'A', 'D'}), 0.08823529411764706)]\n"
     ]
    }
   ],
   "source": [
    "# Generate the association rules from a list of frequent itemsets.\n",
    "H = generate_rules(F, support_data, min_confidence=0.01, VERBOSE=True)\n",
    "#A:'ACT',B: '6-year Grad. Rate', C:'Average Debt', D:'Non-Need-Based Aid+'\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
